Complete reference documentation for the Vercel AI SDK, covering:

**Foundations**: Generative AI concepts (LLMs, embeddings), 50+ provider ecosystem (OpenAI, Anthropic, Google, Mistral, etc.), three prompt types (text, system, message), tool definitions with Zod/JSON schemas, and streaming for improved UX.

**Getting Started**: Quickstart guides for Next.js App/Pages Router, Node.js, Svelte, Nuxt/Vue, and Expo with complete examples. SDK architecture: Core (provider-agnostic), UI (framework hooks), RSC (experimental). Setup patterns: API routes with `streamText`/`convertToModelMessages`, client hooks (`useChat`, `useCompletion`, `useObject`), tool integration with multi-step calling via `stopWhen: stepCountIs(n)`.

**Agents**: `ToolLoopAgent` class for multi-step task automation with configurable stop conditions, dynamic tool selection, structured output parsing, and call options for runtime configuration. Loop control via `prepareStep` callbacks, manual loops with `generateText`, and workflow patterns (sequential, routing, parallel, orchestrator-worker, evaluator-optimizer).

**Core Functions**: `generateText`/`streamText` for text generation with tool calling and multi-step loops. `generateObject`/`streamObject` for structured data with output modes (object/array/enum/no-schema). `embed`/`embedMany` for embeddings, `rerank` for document reranking. Experimental: `generateImage`, `transcribe`, `generateSpeech`. Tool definitions with `tool()` helper, dynamic tools, MCP server integration. Common settings: temperature, topP, topK, penalties, seed, maxRetries, abortSignal. Middleware system for intercepting calls (logging, caching, RAG, guardrails). Provider management via registries and custom providers. Error handling with specific error classes. Testing utilities with mock providers.

**UI Hooks & Components**: `useChat` for streaming chat with message state, tool calling, metadata, persistence, and resumption. `useCompletion` for text completions. `useObject` for structured JSON. Message parts include text, tool calls, reasoning, sources, files. Three tool types: server auto-execute, client auto-execute, user-interaction. Custom data streaming with reconciliation. Transport customization (headers, body, credentials, request transformation). Message validation and conversion utilities. Framework support: React, Svelte, Vue.js, Angular.

**RSC (Experimental)**: `streamUI` for streaming React Server Components from LLM output. `createAI` for client-server state management with AI State (serializable JSON) and UI State (client-only). `createStreamableUI`/`createStreamableValue` for server-to-client streams. Server hooks: `getAIState`, `getMutableAIState`. Client hooks: `useAIState`, `useUIState`, `useActions`, `useStreamableValue`. Multi-step interfaces with tool composition and client interactivity.

**Advanced Patterns**: Prompt engineering (specificity, examples, temperature). Stream cancellation via `abortSignal` and `stop()`. Back-pressure handling with `ReadableStream.pull()`. Caching via middleware or lifecycle callbacks. Multiple streamable UIs with nesting. Rate limiting with Upstash. Language models as routers via function calling. Sequential generations chaining outputs. Deployment to Vercel with environment variables and `maxDuration` configuration.

**API Reference**: Complete type signatures for all functions, hooks, and utilities. Error classes with type-safe detection via `.isInstance()`. Message types (ModelMessage, UIMessage) with content parts. Provider registry and custom provider creation. Stream helpers for LangChain and LlamaIndex adapters. Telemetry via OpenTelemetry.

**Troubleshooting**: Solutions for streaming issues (Azure slowness, timeouts, proxies), useChat problems (parsing errors, duplicate messages, stale data), server actions/RSC issues, tool calling errors, error handling patterns, and compatibility issues (TypeScript performance, model version mismatches, Jest configuration).

**AI SDK 6 Beta**: New Agent interface with ToolLoopAgent default implementation. Tool execution approval with dynamic rules. Stable structured output alongside tool calling. Reranking support (Cohere/Bedrock/Together.ai). Call options for runtime agent configuration. Minimal breaking changes from v5.